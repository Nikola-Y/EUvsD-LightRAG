services:
  lightrag:
    container_name: lightrag
    image: ghcr.io/hkuds/lightrag:latest
#    build:
#      context: .
#      dockerfile: Dockerfile
#      tags:
#        - ghcr.io/hkuds/lightrag:latest
    ports:
      - "${PORT:-9621}:9621"
    volumes:
      - ./data/rag_storage:/app/data/rag_storage
      - ./data/inputs:/app/data/inputs
      - ./data/tiktoken:/app/data/tiktoken
      - ./config.ini:/app/config.ini
    env_file:
      - .env
    environment:
      - TIKTOKEN_CACHE_DIR=/app/data/tiktoken
#    depends_on:
##      - db
#      - ollama
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

#  ollama:
#    image: ollama/ollama:latest
#    container_name: ollama_service
##    environment:
##      - NVIDIA_VISIBLE_DEVICES=all
##    runtime: nvidia
#    ports:
#      - "11434:11434" # порт для API Ollama
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: all
#              capabilities: [gpu]